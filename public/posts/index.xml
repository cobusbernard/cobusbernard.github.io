<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on </title>
    <link>//localhost:1313/posts/</link>
    <description>Recent content in Posts on </description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 28 May 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="//localhost:1313/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Migrating my Jekyll blog to Hugo with Gen-AI</title>
      <link>//localhost:1313/posts/2024-05-28/migrating-jekyll-to-hugo/</link>
      <pubDate>Tue, 28 May 2024 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/posts/2024-05-28/migrating-jekyll-to-hugo/</guid>
      <description>I&amp;rsquo;ve been neglecting my blog, and decided it is time to start writing again. So like any good software developer, I don&amp;rsquo;t actually write a post, I start by tinkering with my blog setup. I initially ran it as a Jekyll generated static site on GitHub using GitHub Pages, and then as part of a live-stream, moved it to use AWS Amplify to host it in on of my many AWS accounts.</description>
    </item>
    <item>
      <title>Remapping the Home and End keys on OSX</title>
      <link>//localhost:1313/posts/2017-02-09/osx-home-end-keys/</link>
      <pubDate>Thu, 09 Feb 2017 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/posts/2017-02-09/osx-home-end-keys/</guid>
      <description>The Problem As I was pasting something into Chrome this morning, I, once again, expected the Home key to take me to the start of the URL. It. Did. Not. So I decided that I won&amp;rsquo;t be able to change this ingrained behaviour and need to fix it. First Google hit led me to a post by Damian Guard that I will be pasting below to keep as notes for myself.</description>
    </item>
    <item>
      <title>Yak Shaving - Makefiles</title>
      <link>//localhost:1313/posts/2017-02-05/yak-shaving-makefiles/</link>
      <pubDate>Sun, 05 Feb 2017 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/posts/2017-02-05/yak-shaving-makefiles/</guid>
      <description>The Problem I woke up this morning wanting to start on a long post about Terraform and how I ended up with the structure shown in my repo. I recently reinstalled my Macbook using Netatalk for a timemachine , and as I fired up my vagrant image, it started to pull down the Ubuntu box first and then started configuring it. This is very useful, but it is slow. And it broke.</description>
    </item>
    <item>
      <title>Setting up a Timemachine server using Mesos/Marathon</title>
      <link>//localhost:1313/posts/2017-01-15/timemachine-backups/</link>
      <pubDate>Sun, 15 Jan 2017 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/posts/2017-01-15/timemachine-backups/</guid>
      <description>I am currently unable to upgrade to the latest version of Slack due to this bug. That combined with my user profile confusion (originally I set up using a US account, then changed to an South African one) that causes requests to update to versions of iPhoto which aren&amp;rsquo;t available in my region made me decide that it is time for a reformat.&#xA;To create a full backup to my raid&amp;rsquo;ed server, I need to set up netatalk.</description>
    </item>
    <item>
      <title>Securing AWS environments using role switching</title>
      <link>//localhost:1313/posts/2016-09-03/aws-multi-account/</link>
      <pubDate>Sat, 03 Sep 2016 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/posts/2016-09-03/aws-multi-account/</guid>
      <description>I&amp;rsquo;ve been working with multiple AWS accounts for the last few months between various organisations. Logging into each one when I need to make a change quickly became tedious and slow. Each environment (dev, test, staging, production) has their own AWS account. The need to log in stems from taming the infrastructure with Terraform for systems that have been set up by hand and dealing with the discrepancies between them, so I tend to jump between dev and staging very often.</description>
    </item>
    <item>
      <title>Getting Glusterd to start at boot on Centos</title>
      <link>//localhost:1313/posts/2016-06-12/centos-gluster-startup/</link>
      <pubDate>Sun, 12 Jun 2016 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/posts/2016-06-12/centos-gluster-startup/</guid>
      <description>I&amp;rsquo;ve been working on a pair of Centos servers using GluserFS for a volume that is shared by various other servers. Each time the server reboots, I had to log in and manually start the service. Turns out this is due to the networking no yet being started when the glusterd service starts. I found this post with the solution:&#xA;Execute systemctl enable NetworkManager-wait-online Add the following to /lib/systemd/system/crond.service under [Unit]: Requires=network.</description>
    </item>
    <item>
      <title>Upgrading a Chef cookbook with Berkshelf</title>
      <link>//localhost:1313/posts/2016-02-18/upgrading-berks-dependency-issue/</link>
      <pubDate>Thu, 18 Feb 2016 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/posts/2016-02-18/upgrading-berks-dependency-issue/</guid>
      <description>I just upgraded my chef-clients via the omnibus_updater cookbook when things started breaking:&#xA;192.168.5.5 [2016-02-18T21:41:13+02:00] WARN: Current apt_package[apt-transport-https]: /var/chef/cache/cookbooks/datadog/recipes/repository.rb:24:in `from_file&amp;#39; 192.168.5.5 192.168.5.5 ================================================================================ 192.168.5.5 Recipe Compile Error in /var/chef/cache/cookbooks/chef-wrapper-omnibus-updater/recipes/default.rb 192.168.5.5 ================================================================================ 192.168.5.5 192.168.5.5 NameError 192.168.5.5 --------- 192.168.5.5 uninitialized constant Chef::REST 192.168.5.5 192.168.5.5 Cookbook Trace: 192.168.5.5 --------------- 192.168.5.5 /var/chef/cache/cookbooks/omnibus_updater/libraries/omnitrucker.rb:84:in `url&amp;#39; 192.168.5.5 /var/chef/cache/cookbooks/omnibus_updater/recipes/downloader.rb:27:in `from_file&amp;#39; 192.168.5.5 /var/chef/cache/cookbooks/omnibus_updater/recipes/default.rb:25:in `from_file&amp;#39; 192.168.5.5 /var/chef/cache/cookbooks/chef-wrapper-omnibus-updater/recipes/default.rb:27:in `from_file&amp;#39; 192.168.5.5 192.168.5.5 Relevant File Content: 192.168.5.5 ---------------------- 192.168.5.5 /var/chef/cache/cookbooks/omnibus_updater/libraries/omnitrucker.rb: 192.168.5.5 192.168.5.5 77: if(url_or_node.</description>
    </item>
    <item>
      <title>Parameterizing Web.config</title>
      <link>//localhost:1313/posts/2016-02-06/parameterizing-webconfig/</link>
      <pubDate>Sat, 06 Feb 2016 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/posts/2016-02-06/parameterizing-webconfig/</guid>
      <description>Most people would have experienced the issue of setting values in web.config for a project on different environments, i.e. the connection string for the database. My first attempt at resolving this was to simply create multiple configurations and build the appropriate one per environment. This has multiple issues: you are including sensitive information in your build artifact, creating different builds for the same version (to allow different values) and tightly coupling your build process to your environment values.</description>
    </item>
    <item>
      <title>NTP on AWS</title>
      <link>//localhost:1313/posts/2015-12-16/ntp-on-aws/</link>
      <pubDate>Wed, 16 Dec 2015 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/posts/2015-12-16/ntp-on-aws/</guid>
      <description>Ran into an issue where a Linux instance running on AWS in a private subnet was not updating the system time via NTP. First check was for the config file, but it had a list of servers, both inside and 1 outside AWS:&#xA;server 0.amazon.pool.ntp.org server 0.us.pool.ntp.org server 1.amazon.pool.ntp.org server 2.amazon.pool.ntp.org From this post (I would like to link to it, but it has been 8.5 years since I wrote this, and only found the missing link today on 2024/05/29) I tried both ntpdate and ntpdate-debian with the following results:</description>
    </item>
    <item>
      <title>Using the Git tag as a version number via PSake</title>
      <link>//localhost:1313/posts/2015-04-04/gitflow-semver-psake/</link>
      <pubDate>Sat, 04 Apr 2015 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/posts/2015-04-04/gitflow-semver-psake/</guid>
      <description>I have been spending most of my time splitting up a monolithic system into separately deployable NuGet packages. The system is monolithic in the sense that there are multiple domains that are deployed as independent WCF services, but all reference the same set of base projects. This means that all the source sits in the same repository. The first step has been to move these common libraries into NuGet packages served from a local network folder and referencing them in each of these solutions as a package rather than project.</description>
    </item>
    <item>
      <title>External MSBuild for WebApi in VS 2013 fails</title>
      <link>//localhost:1313/posts/2015-03-30/msbuild-external-error/</link>
      <pubDate>Mon, 30 Mar 2015 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/posts/2015-03-30/msbuild-external-error/</guid>
      <description>Earlier today, I ran into the following error when trying to build a new WebApi solution using the command-line and MSBuild:&#xA;This is odd as v11 is Visual Studio 2012 and don&amp;rsquo;t even have 2012 installed. The issue manifests when you try to build the solution with: msbuild /t:Clean;Rebuild /v:q /p:Configuration=$projectConfig $source_dir\$projectName.sln /p:Platform=&amp;quot;Any CPU&amp;quot;&#xA;The cause and solution is discussed on Stack Overflow - TL;DR version is this is due to adding the feature for older versions of Visual Studio, but then not setting the correct version number.</description>
    </item>
    <item>
      <title>Git checkout error for public repo</title>
      <link>//localhost:1313/posts/2015-02-27/git-checkout-ssh-vs-https/</link>
      <pubDate>Fri, 27 Feb 2015 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/posts/2015-02-27/git-checkout-ssh-vs-https/</guid>
      <description>One of those djissis duh moments - trying to check out a public git repo, but failing due to authentication &amp;hellip;&#xA;git clone git@github.com:cobusbernard/Scripts.git Cloning into &amp;#39;Scripts&amp;#39;... Warning: Permanently added the RSA host key for IP address &amp;#39;192.30.252.131&amp;#39; to the list of known hosts. Permission denied (publickey). fatal: Could not read from remote repository. Please make sure you have the correct access rights and the repository exists. So I checked my ssh setup / keys, but nothing in there looks dodgy:</description>
    </item>
    <item>
      <title>Replacing mdadm drive</title>
      <link>//localhost:1313/posts/2015-02-19/mdadm-replace-drive/</link>
      <pubDate>Thu, 19 Feb 2015 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/posts/2015-02-19/mdadm-replace-drive/</guid>
      <description>Update 2016-01-09: In the previous version, I never added the command for creating the array and since then I needed it for a new server. When the array starts rebuilding, it will look like there is a failed drive: this is normal. When it builds from scratch, it is actually doing the rebuild process and will indicate a failed drive until the array is rebuilt.&#xA;# mdadm --create --verbose /dev/md0 --level=5 --raid-devices=3 /dev/sdb1 /dev/sdc1 /dev/sdd1 # cat /proc/mdstat md0 : active raid5 sdd1[3] sdc1[1] sdb1[0] 4294702080 blocks super 1.</description>
    </item>
    <item>
      <title>Moving DNS to Amazon Route 53, Dynamic Updates</title>
      <link>//localhost:1313/posts/2015-02-17/route-53-dns-update-script/</link>
      <pubDate>Tue, 17 Feb 2015 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/posts/2015-02-17/route-53-dns-update-script/</guid>
      <description>In my previous post, I set up OpenVPN on my home network and everything was awesome. Until this morning: I could not connect to my VPN. I had forgotten to set up some kind of dynamic DNS updater for it. That should be easy enough, I had previously done this using DynDNS. Only problem was that the service is no longer free. This shouldn&amp;rsquo;t be too much of a problem as I have a couple of my own domains - yes, I will one day still get round to finishing my pet project &amp;lsquo;Tinkle Tones&amp;rsquo; ;)</description>
    </item>
    <item>
      <title>Home VPN with OpenVPN</title>
      <link>//localhost:1313/posts/2015-02-14/openvpn-home/</link>
      <pubDate>Sat, 14 Feb 2015 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/posts/2015-02-14/openvpn-home/</guid>
      <description>Having just set up an external VPN to pretend to be in the US, I wanted one to get into my home network as well when on the road. I ran into the issue while in the USA recently where I was unable to purchase Steam games as their servers picked up that I was in the States, but my payment method was South African. Never thought I would need to spoof my own IP Address to pretend to be in South Africa.</description>
    </item>
    <item>
      <title>Personal VPN - OpenVPN in Docker on DigitalOcean</title>
      <link>//localhost:1313/posts/2015-02-13/openvpn-on-digital-ocean/</link>
      <pubDate>Fri, 13 Feb 2015 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/posts/2015-02-13/openvpn-on-digital-ocean/</guid>
      <description>I was playing around on a random site today, when I received the message This content is not available in your country yet. As a South African, we run into this a lot as our online presence it not that large and most international companies do not feel it is financially viable to run their services here. So I decided it is time to get a VPN going to avoid this.</description>
    </item>
    <item>
      <title>Converting Putty keys to OpenSSH</title>
      <link>//localhost:1313/posts/2015-02-08/convert-putty-keys-to-openssh/</link>
      <pubDate>Sun, 08 Feb 2015 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/posts/2015-02-08/convert-putty-keys-to-openssh/</guid>
      <description>I was playing with Docker yesterday and needed to convert a key that I had been using in Windows with Putty for a while. First attempt with puttygen didn&amp;rsquo;t work at all, then I found this Stack Overflow post, copying the details here so I know where to find it next time :)&#xA;To install the required tools, use&#xA;Ubuntu: sudo apt-get install putty-tools OSX: brew install putty After the required tools have been installed, use the following 2 commands to extract the private and public portion of the key:</description>
    </item>
    <item>
      <title>Basic Jekyll GitHub Blog</title>
      <link>//localhost:1313/posts/2015-01-26/basic-github-jekyll-blog/</link>
      <pubDate>Mon, 26 Jan 2015 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/posts/2015-01-26/basic-github-jekyll-blog/</guid>
      <description>So I finally got round to sorting out the tech blog. I chose to use Jekyll rather than WordPress as I didn&amp;rsquo;t want to deal with constant updates, security vulnerabilities and backing up of the site. Jekyll generates a static site based on the posts created, but still has the advantages of a CMS like tags and categories. Posts are written using Markdown in a plain text file, making it very easy to do the formatting.</description>
    </item>
    <item>
      <title>Linux SSH rate limiting</title>
      <link>//localhost:1313/posts/2013-01-28/ssh-rate-limit/</link>
      <pubDate>Mon, 28 Jan 2013 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/posts/2013-01-28/ssh-rate-limit/</guid>
      <description>Everyone who has an SSH port open to the world knows the amount of brute force attempts you will get. It doesn’t matter if you only accept keys, the script kiddies will still try. Easiest fix for this is rate limiting: you can only attempt to login 3 times per 10 minutes. This does not include successful logins, only failed ones. To do this, use the following IPTables commands:&#xA;sudo iptables -A INPUT -p tcp --dport 22 -m state --state NEW -m recent --set --name SSH --rsource sudo iptables -A INPUT -m recent --update --seconds 600 --hitcount 4 --rttl --name SSH --rsource -j DROP sudo iptables-save &amp;gt; /etc/iptables_rules Add the following to /etc/rc.</description>
    </item>
    <item>
      <title>Using SSH Config</title>
      <link>//localhost:1313/posts/2012-04-12/ssh-config-multiple-keys/</link>
      <pubDate>Thu, 12 Apr 2012 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/posts/2012-04-12/ssh-config-multiple-keys/</guid>
      <description>If you use SSH on Linux a lot, you will know that having to specify the key each time you want to access a server is a pain. You really don&amp;rsquo;t want to have a single key for all servers as you would need to revoke it globally in the event that it was compromised. The ssh config file allows you to specify multiple values to use for specific hosts:</description>
    </item>
    <item>
      <title>Chrome as default browser in Xubuntu</title>
      <link>//localhost:1313/posts/2012-04-10/chrome-default-xubuntu/</link>
      <pubDate>Tue, 10 Apr 2012 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/posts/2012-04-10/chrome-default-xubuntu/</guid>
      <description>If you need to set Chrome as the default browser in Xubuntu, run the following from your terminal:&#xA;gconftool-2 --type string -s /desktop/gnome/url-handlers/http/command &amp;#34;google-chrome %s&amp;#34; </description>
    </item>
    <item>
      <title>Install Java JDK using terminal</title>
      <link>//localhost:1313/posts/2012-03-27/terminal-install-java-ubuntu-10.10/</link>
      <pubDate>Tue, 27 Mar 2012 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/posts/2012-03-27/terminal-install-java-ubuntu-10.10/</guid>
      <description>To install the Java JDK using only the terminal, follow the following steps:&#xA;Download the JDK from:&#xA;http://www.oracle.com/technetwork/java/javase/downloads/java-se-jdk-7-download-432154.html Then run the following commands (change the filename as required):&#xA;tar -xvf jdk-7-linux-i586.tar.gz sudo mv ./jdk1.7.0 /usr/lib/jvm/jdk1.7.0 sudo update-alternatives --install /usr/bin/java java /usr/lib/jvm/jdk1.7.0/jre/bin/java 1 sudo update-alternatives --config java sudo update-alternatives --install /usr/bin/javac javac /usr/lib/jvm/jdk1.7.0/bin/javac 1 sudo update-alternatives --config javac To test that everything is working:&#xA;java -version Should output:&#xA;java version &amp;#34;1.7.0&amp;#34; Java(TM) SE Runtime Environment (build 1.</description>
    </item>
    <item>
      <title>Migrating repo from SVN to Git RPC error</title>
      <link>//localhost:1313/posts/2012-02-04/git-rpc-error/</link>
      <pubDate>Sat, 04 Feb 2012 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/posts/2012-02-04/git-rpc-error/</guid>
      <description>While I was working on Dementium II HD, I wanted to migrate the repository from SVN to Git. It was being hosted on a machine in the one studio and served the external developers over a 10mbit ADSL connection. The upstream rate is ~400kbit, so imagine trying to checkout a 26GB repository. I ran into the following error when I tried to import the SVN repo into a Git one:</description>
    </item>
    <item>
      <title>Ubuntu on Hyper-V</title>
      <link>//localhost:1313/posts/2011-07-25/ubuntu-on-hyper-v/</link>
      <pubDate>Mon, 25 Jul 2011 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/posts/2011-07-25/ubuntu-on-hyper-v/</guid>
      <description>Getting Ubuntu to run on Hyper-V was a bit of an issue for Windows Server 2008, here are some things to look for. In the boot menu, add vga16fb.modeset=0 to the boot options by hitting F6 to disable framebuffer mode that is really slow under Hyper-V.&#xA;Do normal install, don’t worry about the red “can’t find network issue”.&#xA;Enable the Hyper-V modules:&#xA;echo &amp;#34;hv_vmbus&amp;#34; &amp;gt;&amp;gt; /etc/initramfs-tools/modules echo &amp;#34;hv_storvsc&amp;#34; &amp;gt;&amp;gt; /etc/initramfs-tools/modules echo &amp;#34;hv_blkvsc&amp;#34; &amp;gt;&amp;gt; /etc/initramfs-tools/modules echo &amp;#34;hv_netvsc&amp;#34; &amp;gt;&amp;gt; /etc/initramfs-tools/modules update-initramfs –u Disable Framebuffer (otherwise the text screen scrolls by like a 9600 modem)</description>
    </item>
  </channel>
</rss>
